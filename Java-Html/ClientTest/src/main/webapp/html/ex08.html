<!DOCTYPE html>
<html lang="ko">
<head>
	<meta charset="UTF-8">
	<title>Insert title here</title>
</head>
<body>
	<!-- ex08_p.html -->
	<!-- 
		<p>, paragraph
		- 문단 태그
		- 텍스트 집합
		- 쌍태그, 혼합형
		
		p.align
		- horizontal alignment, 내용물 수평정렬
		- center, left, right, justify(양쪽정렬)
	
	
	 -->
	 <p>AGI로 가는 과정을 낙관하는 이유에 대해 올트먼은 3가지 근거를 들었다. 그는 “AI 모델의 지능은 훈련과 실행에 사용한 자원만큼 발전한다”며 “현재까지 일정 금액을 지출하면 지속적이고 예측 가능한 성능 향상이 가능하다는 것이 입증됐고 이런 스케일링 법칙(Scaling Law)이 여러 차원에서 매우 정확하게 작동한다”고 밝혔다. 이 대목은 최근 중국 딥시크가 오픈 AI 대비 18분의 1 비용으로 비슷한 성능의 AI를 구현했다고 주장한 것에 대한 반박으로도 해석된다.</p>
	 <p align="justify">AGI로 가는 과정을 낙관하는 이유에 대해 올트먼은 3가지 근거를 들었다. 그는 “AI 모델의 지능은 훈련과 실행에 사용한 자원만큼 발전한다”며 “현재까지 일정 금액을 지출하면 지속적이고 예측 가능한 성능 향상이 가능하다는 것이 입증됐고 이런 스케일링 법칙(Scaling Law)이 여러 차원에서 매우 정확하게 작동한다”고 밝혔다. 이 대목은 최근 중국 딥시크가 오픈 AI 대비 18분의 1 비용으로 비슷한 성능의 AI를 구현했다고 주장한 것에 대한 반박으로도 해석된다.</p>
	 <p>AGI로 가는 과정을 낙관하는 이유에 대해 올트먼은 3가지 근거를 들었다. 그는 “AI 모델의 지능은 훈련과 실행에 사용한 자원만큼 발전한다”며 “현재까지 일정 금액을 지출하면 지속적이고 예측 가능한 성능 향상이 가능하다는 것이 입증됐고 이런 스케일링 법칙(Scaling Law)이 여러 차원에서 매우 정확하게 작동한다”고 밝혔다. 이 대목은 최근 중국 딥시크가 오픈 AI 대비 18분의 1 비용으로 비슷한 성능의 AI를 구현했다고 주장한 것에 대한 반박으로도 해석된다.</p>
</body>
</html>






